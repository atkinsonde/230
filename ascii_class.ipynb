{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG4shwJ3sp26+WlUekl95B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atkinsonde/230/blob/main/ascii_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code that we used in GEOG/EOS 230 class**<br>\n",
        "**Thursday Jan 18 2024**\n",
        "\n",
        "Recall that we looked at a number of types of ASCII files along with a variety of the pandas read functions.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V6fjcfeiocbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##What is coding?\n",
        "Before we begin...\n",
        "One thing I haven't made clear is why we are coding at all, and what exactly these pandas reading functions are doing. We can compare coding to opening a dataset using a spreadsheet. With a spreadsheet we can see the data in the cells. However, the data still have to be in a format that excel understands. Some are simple: excel understands a csv file and automatically gives a separate cell for each value between commas on each row. That seems pretty straightforward because you can just , but excel is still undergoing a process of *importing* the data so it is compatible with its format. It is less obvious because we can still see all the data in the sheet.\n",
        "\n",
        "\n",
        "We need to convert our dataset into a format that python understands. By \"understanding\" I mean a format that it can operate its functions with. Data that we convert, or read in, is assigned to a variable. Recall that this is a process whereby python opens up a space in memory, reserves it, and gives it the name that we just gave it. This is what \"reading\" means, and what all of these \"read_XXX()\" functions do in pandas - they convert different file types into a form python can understand.\n",
        "\n",
        "\n",
        "From there, we can now do all our stats, plots, and analyses on the data stored in the new variable.\n"
      ],
      "metadata": {
        "id": "9j0fMis1pPHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount class files to your COLAB drive\n",
        "Here is how to get files into your colab so you can refer to them in your code. To do this we will be using the *GitHub repository* I have set up for the class. GitHub is a major professional code \"repo\" and team (or individual) development environment.\n",
        "\n",
        "\n",
        "1.   Run this code: ` !git clone https://github.com/atkinsonde/230.git` in one of your cells. I've already put it in. Click in the cell and type the Control key (CTRL)+Enter at the same time to run the code in any one cell (OR just click on the black circle with the triangle).\n",
        "\n",
        "2.   Once you have run the git code look on the menu on the left. Look for the key symbol and click the folder underneath to open up a window to the left of your code window (if the window is already open, clicking the folder will collapse it and widen your coding area).\n",
        "\n",
        "3.   With the window open, you will see at the top the word \"Files\" and a series of four icons below it. Below, you will see a folder called \"sample_data\". Click on the refresh folder icon (the one with the little circle arrow on it, not the recycle one). Another folder will appear called \"230\". (The little triangles on the left will rotate down when the folders are open). <br><br>\n",
        "\n",
        "4.   If you click on \"230\" you will see a sub-folder called \"ascii_class\". If you click on that, you will see a series of files. These are the files we worked with in class.\n",
        "\n",
        "5.   Your path will therefore be: \"230/ascii_class/FILENAME.EXT\", where \"FILENAME.EXT\" is replaced with the filename you want, such as \"230/ascii_class/combined.json\". Look at the code I have below.\n",
        "\n",
        "\n",
        "The \"refresh\" folder icon looks like this: <br>\n",
        "\n",
        "![refresh_folder.PNG](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFQAAABPCAYAAAB1euKZAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAKmSURBVHhe7dnfa3lxHMfx/atyQUm07Gau5EYp5cKNlCs3mwvSptT8KMXFSo0S29Vqyo2QuDDe3z6ffSyWNfV9dY6j17PemTOfc/LYsXF2JQwaQcERFBxBwREUHEHBERQcQcERFBxBwREUHEHBERQcQcERFBxBwREUHEHBERQcQcERFBxBwREUHEHBERQcQcERFBxBwREUHEHBERSc5aClUkmur6/F5XL9OqFQSCaTiVnhrCwFfXl5OQp4bG5ubhyJaimoOjuP4f02CrVQKJw0jUZDFouFOZJ9WQqqnvgxONQEAgGZzWbmaPZ0UaBqnp6ezNHsyTZQdLv9qmPYGUHBERTcxYDGYjE9zWbTbLGniwE9lxwJ2u12JZ/PSzKZ1Le9Xk9vr1Qqet/q1q4cBareY8bj8e997E8ikdC46muCntByudSfnNTaSCQij4+P+sysVqv6/m6/agh6QqlUSq+7u7uT7XZrtn69zNWZ6fV6CXpq8/lcrwmHwweYKnVlarfP3RD0j1qtll6jXuY/e3t7k36/fzB2XqVyBGi73dZrHh4ezJbzzVLQ/ct3CveUUX+MBoOBXpPJZMyejlev1/Wa6XRqtlifpaCdTucb9NQpFouyXq8lGAyK2+2W8Xhs9nbYcDjUj1fvBH7+nrUyS0HVE81ms3/+C2R/fD6frFYrqdVq+r6CHY1GZo9fPT8/i9/v198vl8tmqz1ZCvo/qR9GLpfTaOpMjUaj+rP77e3tN/79/b1sNhuzwp4cA7pLvZHfR/R4PJJOp+Xj48M8wt4cB7rr/f1dXl9f5fPz02w5jxwLeq4RFBxBwREUHEHBERQcQcERFBxBwREUHEHBERTclbowy8ENz1BwBAVHUHAEBUdQcAQFR1BwBAVHUHAEBUdQcASFJvIPJtuJosBjdYQAAAAASUVORK5CYII=)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L1C2ibr51Hc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atkinsonde/230.git"
      ],
      "metadata": {
        "id": "4535T9Rhj-Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries\n",
        "\n",
        "After \"mounting\" the data drive using the !git, the next thing to do is to import the libraries that contain the functions we will need. Recall that \"base\" python has a basic suite of progam control commands and functions, but not too much else for specific uses. To get that extra functionality we have to specify particular libraries.\n",
        "\n",
        "The command is `import LIBNAME` and usually we include `as SHORT_LIBNAME` to give it a handle that is easier to type out.\n",
        "\n",
        "The whole thing becomes `import pandas as pd` or `import numpy as np` and so on.\n",
        "\n",
        "Run this code:"
      ],
      "metadata": {
        "id": "yyfJlVAvd2uu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ba78k-rAoP0S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that when you run it you can see the black circle icon on the left take on a \"busy\" appearance. When the code is finished, it returns to a black circle with an arrow. Note as well that no output appears for this particular command. You know it has run correctly if it gives you no output.\n",
        "\n"
      ],
      "metadata": {
        "id": "MDvEbpeIfYM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##First reader: `pd.read_csv()`\n",
        "\n",
        "Now for the first pandas reader, `pd.read_csv()`"
      ],
      "metadata": {
        "id": "MPQVm1Mtoxm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"230/ascii_class/oliver_dump_2016-2019.csv\")"
      ],
      "metadata": {
        "id": "6VyHtTQVxpkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reads in some weather station data from a station I had in a merlot field in a vineyard near Oliver, BC. It is a standard, simple-structure csv file. Each row is one observation, and each observation is made for several variables.\n",
        "\n",
        "Run this and note three things:\n",
        "1. A new cell with output from the command appears. This is what you could call \"output to the screen\".  \n",
        "2. All you have is output to the screen - no new variable storing the data has been created.\n",
        "3. I don't always want to see the output; if you want to remove it, move your mouse over the little icon (box with a right-pointing arrow), it will turn into an X - click that and the output box will disappear.\n",
        "\n",
        "Now let's save these data to a variable. Run the cell below:"
      ],
      "metadata": {
        "id": "UKgU9IQumBTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merlot_data = pd.read_csv(\"230/ascii_class/oliver_dump_2016-2019.csv\")"
      ],
      "metadata": {
        "id": "RSc6okHRm5CC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note this time there was no output. But, if you click on the {*X*} icon on the far left edge, which shows you your variables, you will see a new variable has appeared. It's name is merlot_data and its \"shape\" is (14608,7), which means 14,608 rows by 7 columns. Each row is an observation taken on the hour, and each column is a variable.\n",
        "Instead of dumping the output to the screen, because we *assigned* the output to a variable using the = sign, python took the result of the reading process and stored it in the variable."
      ],
      "metadata": {
        "id": "IxwFZ9Mrnw0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reader: pd.read_fwf()\n",
        "\n",
        "The next reader we looked at was the fixed-width field reader. This lets us handle files that my not have a separator but which have a perfectly regular column width structure.\n",
        "\n",
        "This is a more complicated one to set up, so recall I said good coding practice is to build up your solution in parts. Add one thing, run it, make sure it works, then add the next thing, etc. So, the first thing is to make sure the `pd.read_fwf()` works at all for this, and to make sure python can find the file:"
      ],
      "metadata": {
        "id": "XAp4AxXTp3F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_fwf(\"230/ascii_class/event_data_structure.txtx\")"
      ],
      "metadata": {
        "id": "Sv2YcWehq7lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall from our discussion in class that python is reading each row as one big \"string\". It doesn't understand any particular variable. You have to manually specify the column ranges that define each variable, and then you have to provide a name for each variable. Recall we do this with two additional *arguments* to the `pd.read_fwf()` function: `colspecs=` and `names=`. (separate each argument with a comma). I will do the first one and leave it as a self-help exercise for you to do the rest the variables. You will also note that the first row is a header value. Use the online help to find the argument that allows you to skip over rows. Here is that comprehensive website [pandas.pydata.org](https://pandas.pydata.org/docs/user_guide/io.html#)). Search for `read_fwf()`, and note that many of the arguments are the same for a number of the readers.\n",
        "\n",
        "Here is your metadata.<br>\n",
        "There are eight variables in total:\n",
        "- yyyy is a four column year\n",
        "- jjs  is a three column julian day storm event start\n",
        "- jje  is a three column julian day storm event end\n",
        "- dur  is a three column storm event duration in hours\n",
        "- av1  is a three column storm max intensity mean wind speed in m/s\n",
        "- ava  is a three column storm total mean wind speed in m/s\n",
        "- lonnn is a five column longitude (multiplier 0.1)\n",
        "- lat is a three column latitude (multiplier 0.1)\n",
        "\n",
        "(you don't have to apply the multipliers etc).\n",
        "\n",
        "I'll start you off:"
      ],
      "metadata": {
        "id": "OPk9PDGrruSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_fwf(\"230/ascii_class/event_data_structure.txtx\",\n",
        "            colspecs=[(0,4)],\n",
        "            names=['year'])"
      ],
      "metadata": {
        "id": "_zeEdCjrxYNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that all of these pandas readers are creating what is called a *DataFrame* object. `colspecs=` takes a *list* object [] as a variable; that list object in turn contains *tuple* objects with column start and end pairs (and recall python starts counting at 0 and stops one before the end, so 4 will give you up to column #3).\n",
        "\n",
        "You go ahead a finish that, and when it is reading all of the variables and getting rid of the header, save it to a variable and verify it is in your list of variables on the left {X}."
      ],
      "metadata": {
        "id": "IcZeDpXux1WT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2FEy-8Dy35C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}